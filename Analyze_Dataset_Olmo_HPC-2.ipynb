{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4896923-0a60-4520-a7bf-f8aaa364b207",
   "metadata": {},
   "source": [
    "# Analyse Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cad098f-9a22-4561-ae7d-7e5cc13a7586",
   "metadata": {},
   "source": [
    "First, you need to connect to the Ollama server. Use your own acoount information: https://hpcproject.gwdg.de/projects/baaa32d3-6b49-4831-8b75-87ff44056ae0/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b71f27c-fda2-400b-b842-46d3d8f685d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Kill any existing processes\n",
    "!pkill -f ollama\n",
    "time.sleep(2)\n",
    "\n",
    "# Start server\n",
    "process = subprocess.Popen([\n",
    "    '/user/sarah.oberbichler/u18915/bin/ollama', 'serve'\n",
    "], env=os.environ.copy())\n",
    "\n",
    "print(f\"Server started (PID: {process.pid})\")\n",
    "time.sleep(8)\n",
    "\n",
    "# Test server\n",
    "result = subprocess.run([\n",
    "    '/user/sarah.oberbichler/u18915/bin/ollama', 'list'\n",
    "], capture_output=True, text=True)\n",
    "\n",
    "print(f\"Server status: {result.returncode}\")\n",
    "print(f\"Models: {result.stdout}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08aa660f-1fde-429c-8ab4-2d2c08333249",
   "metadata": {},
   "source": [
    "### Load the dataset (SummerSchool_dataset.xlsx).\n",
    "You can find it here: https://github.com/soberbichler/Workshop_QualitativeDataResearch_LLM/blob/main/data/SummerSchool_dataset.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f97b74-2cb2-4eaf-9774-ef058cb10a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openpyxl\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('SummerSchool_dataset.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef7f265-2584-427c-ac27-f2ad79044d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model \n",
    "def warm_up_model():\n",
    "    \"\"\"Warm up the model with simple prompts.\"\"\"\n",
    "    print(\"Warming up model...\")\n",
    "    \n",
    "    for prompt in [\"Hi\", \"What is 2+2?\", \"Say hello\"]:\n",
    "        try:\n",
    "            ask_olmo_api(prompt)\n",
    "            print(\".\", end=\"\", flush=True)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    print(\"\\nWarmup complete!\")\n",
    "\n",
    "warm_up_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b28a07a-8fd1-41a5-94e8-b0796947a13e",
   "metadata": {},
   "source": [
    "### Run the Model\n",
    "\n",
    "Add your prompt and you can also adjust the model parameter\n",
    "\n",
    "After running the cell, fill in the model documentation while waiting (and continue after saving the results)!\n",
    "\n",
    "Model documentation: https://seafile.rlp.net/seafhttp/f/a5b34ec61267408da431/?op=view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf142d9-33a4-4591-9102-8bbf792927d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_olmo_api(text, temperature=0.1, max_tokens=1000):\n",
    "    \"\"\"Simple OLMo API call\"\"\"\n",
    "    prompt = f\"\"\"You are an expert at analyzing historical texts and you hate to summarize. Please find argumentative units in historical articles. Arguments in newspapers are often implicit but should contain a clear premise (with an inclusice claim)\n",
    "OUTPUT FORMAT - EXACTLY these 4 XML tags and NOTHING else:\n",
    "<argument>Original argument text OR \"NA\"</argument>\n",
    "<claim>Core claim (implication) in one sentence OR \"NA\"</claim>\n",
    "<explanation>Why this is an argument OR \"NA\"</explanation>\n",
    "<human_verification_needed>True OR False</human_verification_needed>\n",
    "EXAMPLE WITH ARGUMENT:\n",
    "<argument>Es sind furchtbare Bilder, die sich dabei entrollen. Unter den Trümmern des einen Hause», so erzählt Luigt Barsint im Corrtcre della sera, findet man die Leichen von Unglück lichen, die in anderen Häusern gewohnt baben und die in der Ber- Wirrung de» schrcck.ichen Augenblickes instinktiv bet Fremden Hülfe und Unterschlupf suchten. Niemand erkennt jetzt diese armen Ein dringlinge, ihre Leichen werden nicht reklamiert, und man trägt sie hinunter an de» Strand, wo sie in langer Reihe einer neben den anderen hingebettet weiden, in denselben Tüchern und Decken, in denen sie tbren Tod gesunden.</argument>\n",
    "<claim>The earthquake's chaos led to unidentified victims dying in unfamiliar places.</claim>\n",
    "<explanation>Describes how people fled to other houses seeking help during the disaster, died there, and now cannot be identified or claimed by relatives. Shows cause (panic/confusion) and effect (anonymous deaths).</explanation>\n",
    "<human_verification_needed>False</human_verification_needed>\n",
    "EXAMPLE WITHOUT ARGUMENT:\n",
    "<argument>NA</argument>\n",
    "<claim>NA</claim>\n",
    "<explanation>NA</explanation>\n",
    "<human_verification_needed>FALSE</human_verification_needed>\n",
    "RULES:\n",
    "- NO SUMMARY; ONLY ORIGINAL EXTRACTOM FROM THE TEXT; don't extract anything that is not in the text. Only extract word by word\n",
    "- ONLY output these 4 XML tags\n",
    "- Factual reportings such as \"Dem Vulkanausbruch folgten drei Sturzwellen in etwa 10 Meter Höhe\" are NO arguments\n",
    "- Extract only original text without changes or use NA when you did not find an argument\n",
    "- The claim is not a translation of summary of argument. It should say what the (implicite) argument implies\n",
    "- In cases of uncertainty or ambiguity, say human_verification_needed TRUE\n",
    "- If no argument exists, use NA for all fields except <human_verification_needed>FALSE or TRUE</human_verification_needed>\n",
    "- More than one argumentative unit possible for one article, one unit has one clear claim and all the xml structures\n",
    "\n",
    "Extract the arguments from this text:\n",
    "{text}\"\"\"\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": \"MHKetbi/allenai_OLMo2-0325-32B-Instruct:q5_K_S\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"stream\": False,\n",
    "        \"options\": {\n",
    "            \"temperature\": temperature,\n",
    "            \"num_predict\": max_tokens\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post('http://127.0.0.1:11434/api/chat', json=payload)\n",
    "        return response.json()['message']['content']\n",
    "    except:\n",
    "        return \"Error\"\n",
    "\n",
    "# Apply properly\n",
    "df['model_answer_olmo'] = df['extracted_articles'].apply(lambda x: ask_olmo_api(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc77660-2006-4053-b477-b40e6ed40f6c",
   "metadata": {},
   "source": [
    "### Export the Dataset and name it differently than \"results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a226d226-40fa-4ff4-b4ab-63b3ae540e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('results.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6047510c-46dd-4037-bc12-9f670e80cfbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
