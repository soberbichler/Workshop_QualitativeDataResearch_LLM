{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soberbichler/Workshop_QualitativeDataResearch_LLM/blob/main/Analyze_Dataset_Huggingface_Jobs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Running LLM Jobs via HuggingFace\n",
        "\n",
        "For explanations on Hugginface https://huggingface.co/docs/huggingface_hub/guides/jobs\n",
        "\n"
      ],
      "metadata": {
        "id": "lL56CWXjl3vT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Requirements for Hugging Face Jobs\n",
        "\n",
        "\n",
        "\n",
        "*   Hugging Face Pro account - A paid subscription is required to access job creation features\n",
        "*   Write access token - Generate a token with write permissions from your account settings\n",
        "*   Valid payment method - Jobs consume compute credits based on usage\n",
        "\n",
        "\n",
        "##Authentication Setup\n",
        "\n",
        "\n",
        "\n",
        "*   Create your access token at huggingface.co/settings/tokens (you will be given an API as part of the workshop)\n",
        "*   Ensure the token has \"Write\" permissions enabled\n",
        "*   Save your token as HF_Token under Secrets (where the key symbol is)\n"
      ],
      "metadata": {
        "id": "tJA5bCH8pL9f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analyze our Dataset\n",
        "\n",
        "The dataset is already integrated into the script below. Can you find the position where this happens? Which column of the data is being used for the analysis? Where is the prompt and what model is being used?\n",
        "\n",
        "\n",
        "\n",
        "> ***Answer those questions before you run the script (both cells). After runnung the script, fill in the model documentation while waiting!***\n",
        "\n",
        "Model documentation: https://seafile.rlp.net/seafhttp/f/a5b34ec61267408da431/?op=view\n",
        "\n"
      ],
      "metadata": {
        "id": "YSrf2YqZ_W5_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run the script\n",
        "\n",
        "\n",
        "\n",
        "> ***Don't forget to add your token in your script instead of \"your_token\"***\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dQbxzRQE-bls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import run_job\n",
        "\n",
        "job = run_job(\n",
        "    image=\"pytorch/pytorch:2.6.0-cuda12.4-cudnn9-devel\",\n",
        "    command=[\n",
        "        \"bash\", \"-c\",\n",
        "        \"\"\"\n",
        "        apt-get update && apt-get install -y wget &&\n",
        "        pip install -q \"transformers>=4.51.0\" accelerate bitsandbytes huggingface_hub pandas &&\n",
        "        wget -O SummerSchool_dataset.csv https://raw.githubusercontent.com/soberbichler/Workshop_QualitativeDataResearch_LLM/refs/heads/main/data/SummerSchool_dataset.csv &&\n",
        "        python3 -c \"\n",
        "import os, torch, pandas as pd, datetime, re\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from huggingface_hub import login, upload_file\n",
        "\n",
        "\n",
        "# CONFIGURATION\n",
        "\n",
        "model_name = 'deepseek-ai/DeepSeek-R1-Distill-Qwen-14B'\n",
        "\n",
        "# YOUR PROMPT\n",
        "\n",
        "SYSTEM_PROMPT = '''You are an expert at analyzing historical texts and you do not summarize\n",
        "OUTPUT FORMAT - EXACTLY these 4 XML tags and NOTHING else:\n",
        "<argument>Original argument text OR \"NA\"</argument>\n",
        "<claim>Core claim (implication) in one sentence OR \"NA\"</claim>\n",
        "<explanation>Why this is an argument OR \"NA\"</explanation>\n",
        "<human_verification_needed>True OR False</human_verification_needed>\n",
        "EXAMPLE WITH ARGUMENT:\n",
        "<argument>Es sind furchtbare Bilder, die sich dabei entrollen. Unter den Trümmern des einen Hause», so erzählt Luigt Barsint im Corrtcre della sera, findet man die Leichen von Unglück lichen, die in anderen Häusern gewohnt baben und die in der Ber- Wirrung de» schrcck.ichen Augenblickes instinktiv bet Fremden Hülfe und Unterschlupf suchten. Niemand erkennt jetzt diese armen Ein dringlinge, ihre Leichen werden nicht reklamiert, und man trägt sie hinunter an de» Strand, wo sie in langer Reihe einer neben den anderen hingebettet weiden, in denselben Tüchern und Decken, in denen sie tbren Tod gesunden.</argument>\n",
        "<claim>The earthquake's chaos led to unidentified victims dying in unfamiliar places.</claim>\n",
        "<explanation>Describes how people fled to other houses seeking help during the disaster, died there, and now cannot be identified or claimed by relatives. Shows cause (panic/confusion) and effect (anonymous deaths).</explanation>\n",
        "<human_verification_needed>False</human_verification_needed>\n",
        "EXAMPLE WITHOUT ARGUMENT:\n",
        "<argument>NA</argument>\n",
        "<claim>NA</claim>\n",
        "<explanation>NA</explanation>\n",
        "<human_verification_needed>FALSE</human_verification_needed>\n",
        "RULES:\n",
        "- NO SUMMARY; ONLY ORIGINAL EXTRACTOM FROM THE TEXT; don't extract anything that is not in the text. Only extract word by word\n",
        "- ONLY output these 4 XML tags\n",
        "- Factual reportings are NO arguments\n",
        "- Extract only original text without changes or use NA when you did not find an argument\n",
        "- The claim is not a translation of summary of argument. It should say what the (implicite) argument implies\n",
        "- In cases of uncertainty or ambiguity, say human_verification_needed TRUE\n",
        "- If no argument exists, use NA for all fields except <human_verification_needed>FALSE or TRUE</human_verification_needed>\n",
        "- More than one argumentative unit possible for one aticle, one unit has one clear clame and all the xml structures\n",
        "'''\n",
        "\n",
        "\n",
        "# SETUP\n",
        "\n",
        "\n",
        "hf_token = os.environ.get('HUGGINGFACE_TOKEN')\n",
        "login(token=hf_token)\n",
        "\n",
        "df = pd.read_csv('SummerSchool_dataset.csv', sep=';')\n",
        "print(f'Dataset loaded with {len(df)} rows')\n",
        "\n",
        "\n",
        "# LOAD MODEL\n",
        "\n",
        "print('Loading model...')\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, token=hf_token)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    device_map='auto',\n",
        "    load_in_4bit=True,\n",
        "    torch_dtype=torch.float16,\n",
        "    token=hf_token\n",
        ")\n",
        "print('Model loaded successfully!')\n",
        "\n",
        "\n",
        "# GENERATION FUNCTION\n",
        "\n",
        "\n",
        "def generate_structured_response(model, tokenizer, text_to_analyze):\n",
        "    '''Generate response with exact training format'''\n",
        "\n",
        "    # EXACT format as in training\n",
        "    user_instruction = '''Extract argumentative units in its original form.\n",
        "    Text to analyze:\n",
        "    '''\n",
        "\n",
        "    full_prompt = f'''<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
        "{SYSTEM_PROMPT}<|eot_id|>\n",
        "<|start_header_id|>user<|end_header_id|>\n",
        "{user_instruction}{text_to_analyze[:5500]}<|eot_id|>\n",
        "<|start_header_id|>assistant<|end_header_id|>\n",
        "'''\n",
        "\n",
        "    inputs = tokenizer(full_prompt, return_tensors='pt', truncation=True, max_length=5048).to(model.device)\n",
        "    input_length = inputs['input_ids'].shape[1]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=5000,\n",
        "            temperature=0.1,\n",
        "            do_sample=False,\n",
        "            top_p=0.9,\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "            #repetition_penalty=1.3\n",
        "        )\n",
        "\n",
        "    # Decode ONLY the generated part\n",
        "    generated_tokens = outputs[0][input_length:]\n",
        "    response = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
        "\n",
        "    # Clean the response\n",
        "    response = response.strip()\n",
        "\n",
        "    # If model outputs the prompt again, extract just XML\n",
        "    if '<|begin_of_text|>' in response or '<|start_header_id|>' in response:\n",
        "        # Extract only the XML part\n",
        "        xml_match = re.search(r'(<argument>.*?</human_verification_needed>)', response, re.DOTALL)\n",
        "        if xml_match:\n",
        "            response = xml_match.group(1)\n",
        "\n",
        "    # Extract clean XML structure if it exists\n",
        "    if '<argument>' in response and '</human_verification_needed>' in response:\n",
        "        start_idx = response.find('<argument>')\n",
        "        end_idx = response.rfind('</human_verification_needed>') + len('</human_verification_needed>')\n",
        "        response = response[start_idx:end_idx]\n",
        "\n",
        "    # Validate structure\n",
        "    required_tags = ['<argument>', '</argument>', '<claim>', '</claim>',\n",
        "                     '<explanation>', '</explanation>',\n",
        "                     '<human_verification_needed>', '</human_verification_needed>']\n",
        "\n",
        "    if not all(tag in response for tag in required_tags):\n",
        "        print('  Warning: Using fallback')\n",
        "        response = '''<argument>NA</argument>\n",
        "<claim>NA</claim>\n",
        "<explanation>NA</explanation>\n",
        "<human_verification_needed>NA</human_verification_needed>'''\n",
        "\n",
        "    return response\n",
        "\n",
        "def parse_structured_response(response):\n",
        "\n",
        "    parsed = {}\n",
        "\n",
        "    patterns = {\n",
        "        'argument': r'<argument>(.*?)</argument>',\n",
        "        'claim': r'<claim>(.*?)</claim>',\n",
        "        'explanation': r'<explanation>(.*?)</explanation>',\n",
        "        'verification_needed': r'<human_verification_needed>(.*?)</human_verification_needed>'\n",
        "    }\n",
        "\n",
        "    for key, pattern in patterns.items():\n",
        "        match = re.search(pattern, response, re.DOTALL)\n",
        "        if match:\n",
        "            parsed[key] = match.group(1).strip()\n",
        "        else:\n",
        "            parsed[key] = 'ERROR_MISSING'\n",
        "\n",
        "    # Check if argument exists\n",
        "    has_arg = (\n",
        "        parsed['argument'] != 'NA' and\n",
        "        parsed['argument'] != 'ERROR_MISSING' and\n",
        "        len(parsed['argument']) > 5\n",
        "    )\n",
        "    parsed['has_argument'] = has_arg\n",
        "\n",
        "    return parsed\n",
        "\n",
        "\n",
        "# MAIN PROCESSING LOOP\n",
        "\n",
        "results = []\n",
        "structure_compliance = {'perfect': 0, 'failed': 0}\n",
        "\n",
        "for idx, row in df.iterrows():\n",
        "    text = str(row.get('extracted_articles', ''))\n",
        "\n",
        "    if pd.isna(text) or text.strip() in ['nan', '']:\n",
        "        print(f'Row {idx}: empty, skipping')\n",
        "        continue\n",
        "\n",
        "    print(f'Processing row {idx}...')\n",
        "\n",
        "    try:\n",
        "        # Generate response\n",
        "        response = generate_structured_response(model, tokenizer, text)\n",
        "\n",
        "        # Parse response\n",
        "        parsed = parse_structured_response(response)\n",
        "\n",
        "        # Check structure compliance\n",
        "        if all(parsed[k] != 'ERROR_MISSING' for k in ['argument', 'claim', 'explanation', 'verification_needed']):\n",
        "            structure_compliance['perfect'] += 1\n",
        "            print(f'  ✓ Perfect structure')\n",
        "        else:\n",
        "            structure_compliance['failed'] += 1\n",
        "            print(f'  ✗ Failed structure')\n",
        "\n",
        "        # Store results - USING PARSED VALUES CORRECTLY\n",
        "        result_row = row.to_dict()\n",
        "        result_row['llm_raw_response'] = response[:5000]\n",
        "        result_row['argument'] = parsed['argument']\n",
        "        result_row['claim'] = parsed['claim']\n",
        "        result_row['explanation'] = parsed['explanation']\n",
        "        result_row['human_verification_needed'] = parsed['verification_needed']\n",
        "        result_row['has_argument'] = parsed['has_argument']\n",
        "        result_row['processed_row_index'] = idx\n",
        "        result_row['model_used'] = model_name\n",
        "        results.append(result_row)\n",
        "\n",
        "        # Show result\n",
        "        if parsed['has_argument']:\n",
        "            arg_text = parsed['argument']\n",
        "            preview = arg_text[:50] + '...' if len(arg_text) > 50 else arg_text\n",
        "            print(f'  Found: {preview}')\n",
        "        else:\n",
        "            print(f'  No argument (NA)')\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f'  Error: {str(e)}')\n",
        "        result_row = row.to_dict()\n",
        "        result_row['llm_raw_response'] = 'ERROR'\n",
        "        result_row['argument'] = str(e)\n",
        "        result_row['claim'] = 'ERROR'\n",
        "        result_row['explanation'] = 'ERROR'\n",
        "        result_row['human_verification_needed'] = 'True'\n",
        "        result_row['has_argument'] = False\n",
        "        result_row['processed_row_index'] = idx\n",
        "        result_row['model_used'] = model_name\n",
        "        results.append(result_row)\n",
        "\n",
        "\n",
        "# COMPLIANCE REPORT\n",
        "\n",
        "\n",
        "total = sum(structure_compliance.values())\n",
        "if total > 0:\n",
        "    print('\\\\n' + '='*50)\n",
        "    perf = structure_compliance['perfect']\n",
        "    fail = structure_compliance['failed']\n",
        "    print(f'STRUCTURE COMPLIANCE:')\n",
        "    print(f'  Perfect: {perf}/{total} ({perf/total*100:.1f}%)')\n",
        "    print(f'  Failed: {fail}/{total} ({fail/total*100:.1f}%)')\n",
        "    print('='*50)\n",
        "\n",
        "\n",
        "# SAVE AND UPLOAD\n",
        "\n",
        "\n",
        "output_df = pd.DataFrame(results)\n",
        "output_df.to_csv('output_analysis_structured.csv', index=False)\n",
        "print(f'\\\\nSaved {len(output_df)} results to CSV')\n",
        "\n",
        "\n",
        "# Upload to Hugging Face\n",
        "timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "filename = f'llm_structured_results_{timestamp}.csv'\n",
        "\n",
        "try:\n",
        "    print(f'\\\\nUploading as {filename}...')\n",
        "    upload_file(\n",
        "        path_or_fileobj='output_analysis_structured.csv',\n",
        "        path_in_repo=filename,\n",
        "        repo_id='oberbics/jobs',\n",
        "        repo_type='dataset',\n",
        "        token=hf_token,\n",
        "        commit_message=f'Structured LLM analysis - {timestamp}'\n",
        "    )\n",
        "    print(f'\\\\n✅ SUCCESS! File uploaded: {filename}')\n",
        "    print(f'📥 Download: https://huggingface.co/datasets/oberbics/jobs/resolve/main/{filename}')\n",
        "except Exception as e:\n",
        "    print(f'\\\\n❌ Upload failed: {str(e)}')\n",
        "\n",
        "print(f'\\\\n🎯 Job complete! Processed {len(output_df)} rows')\n",
        "\"\n",
        "        \"\"\"\n",
        "    ],\n",
        "    flavor=\"a100-large\",\n",
        "    env={\"HUGGINGFACE_TOKEN\": \"your_token\"}\n",
        ")\n",
        "\n",
        "print(f\"Job submitted! ID: {job.id}\")\n",
        "print(f\"Monitor at: https://huggingface.co/jobs/oberbics/{job.id}\")"
      ],
      "metadata": {
        "id": "4hcwFxaQZmEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Monitor the job and get the results!\n",
        "\n",
        "Open the CSV file, copy it into a .txt file and open it in excel and safe the results. To open it in Excel, open a new file, go to \"data\" and the data tab and click From Text/CSV\n"
      ],
      "metadata": {
        "id": "N2zqQffkBmkw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import inspect_job, fetch_job_logs\n",
        "import time\n",
        "\n",
        "# Poll job status until it's done\n",
        "while True:\n",
        "    status = inspect_job(job_id=job.id).status.stage\n",
        "    print(f\"Job status: {status}\")\n",
        "    if status in (\"COMPLETED\", \"ERROR\"):\n",
        "        break\n",
        "    time.sleep(10)\n",
        "\n",
        "# Fetch logs after completion\n",
        "print(\"\\n=== Job logs ===\")\n",
        "logs = list(fetch_job_logs(job_id=job.id))\n",
        "for line in logs:\n",
        "    print(line)\n"
      ],
      "metadata": {
        "id": "9EAgsLe5dh0Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}